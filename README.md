# ml_cs231n_cpp

This repo contains my c++ implementation of the SVM and Softmax loss functions in addition to the simple two-layer Neural Network.
I developed them for vizualization and understanding while doing CS231n from Stanford University course in 2016.

This project contains:

1. Implementation of the SVM and Softmax loss
2. Implementation of the 2 layer neural network
3. Multiple normalization possibilities (mean subtraction, normalization, standartization)
4. Adam weight update
5. Fisherâ€“Yates shuffle algorithm for batching
6. Simple ensample executable that loads saved weights from the network training and averages at teset time

## SVM and Softmax loss
![svmandsoftmaxloss](https://github.com/Logrus/ml_cs231n_cpp/raw/master/images/svm_softmax_viz.png)

## Two layer Neural Network
![twolayernetwork](https://github.com/Logrus/ml_cs231n_cpp/raw/master/images/two_layer_nn_viz.png)
